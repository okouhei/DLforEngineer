{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.1_simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDnlmvQuga_I"
      },
      "source": [
        "# 準備\n",
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br0bskKegKSB",
        "outputId": "90b9368f-98b6-4e03-e03a-101dfbc027f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxtg9y4GhEVi"
      },
      "source": [
        "# sys.pathの設定\n",
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5lhRHOGhKt4"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4')\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4/lesson_3')\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4/lesson_4')\n",
        "sys.path.append('/content/drive/My Drive/DNN_code_colab_lesson_3_4/common')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01JUTEMYhMXS"
      },
      "source": [
        "# simple RNN after\n",
        "##　バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OrqOy6sXhkM9",
        "outputId": "811feebf-1a38-46d3-cd6e-1d28ed7dcaa9"
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# He\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1])    \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1])    \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.6934849578276434\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "100 + 74 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8831674683527239\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 0 0 1]\n",
            "97 + 96 = 231\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.1033565450733267\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "112 + 58 = 116\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.8956195327532253\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "82 + 35 = 127\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.346225472480175\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "31 + 121 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8481822426775383\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "64 + 36 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.9592799244060719\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "14 + 93 = 186\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.7595889923388401\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "100 + 76 = 144\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0890799208944233\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "7 + 83 = 254\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.7270967878961504\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 0 0 0 1 0 0 0]\n",
            "7 + 1 = 6\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8548014990961741\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "79 + 74 = 159\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9479023202710637\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "62 + 26 = 36\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.5341090287900017\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 0 0 1 0 1 0 0]\n",
            "18 + 2 = 20\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.7428212887867466\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "123 + 2 = 253\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8002089462145745\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "56 + 17 = 33\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.5543844234168647\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "118 + 14 = 125\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0723661603046408\n",
            "Pred:[1 1 1 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "16 + 126 = 232\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.8085880377204643\n",
            "Pred:[1 1 0 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 1 0]\n",
            "112 + 118 = 196\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.8305221137262504\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "105 + 16 = 97\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.7671685994641673\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "70 + 118 = 184\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.7091683131947176\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 1 0 1]\n",
            "57 + 36 = 89\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.965803718262625\n",
            "Pred:[1 1 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "49 + 124 = 193\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.1348979827103507\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "126 + 54 = 192\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.5551594965832363\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "38 + 64 = 102\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.7632635411428694\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "80 + 50 = 96\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.5456001051211385\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 1]\n",
            "127 + 96 = 159\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.5670685508475343\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "26 + 13 = 63\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.6040487754016022\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 1 1 0 1 1 0 0]\n",
            "122 + 114 = 140\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.0449629052791465\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "101 + 28 = 113\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.727682701031395\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "113 + 16 = 225\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.1360276438166936\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "95 + 41 = 100\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.7471370848445468\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "29 + 106 = 167\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.7280884631960729\n",
            "Pred:[1 1 0 1 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "126 + 100 = 210\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.48422172152918314\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "50 + 77 = 127\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.705666230904906\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "122 + 78 = 128\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.0001442565081258\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "31 + 101 = 178\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.36626451097285045\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "44 + 44 = 80\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.33304549103461734\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "112 + 37 = 149\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.29698659685555234\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "23 + 86 = 109\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.5435788027329216\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "55 + 43 = 66\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.3638749779915099\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "67 + 57 = 124\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.40780867687956507\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "95 + 87 = 166\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.3008773471124374\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "45 + 28 = 73\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.4785964563830399\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "94 + 19 = 97\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.28295829089600155\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "74 + 63 = 137\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.11471145884804819\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "90 + 114 = 204\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.08223235524053442\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "65 + 40 = 105\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.2346621631204113\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "113 + 54 = 167\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.09703959434134184\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "74 + 89 = 163\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.12978195064414397\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "46 + 71 = 117\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.13732972223565096\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "45 + 117 = 162\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.1930021999611558\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "62 + 83 = 145\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.06912406317118595\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "2 + 69 = 71\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.040961738917628006\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "36 + 120 = 156\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.11403760659066907\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "23 + 55 = 78\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.09575645091725554\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "60 + 39 = 99\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.029234273091580366\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "80 + 40 = 120\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.03538122843883991\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "79 + 94 = 173\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.05868771633135177\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "75 + 101 = 176\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.020749325702799446\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "17 + 125 = 142\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.09847243642309407\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "126 + 65 = 191\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.03151288045025752\n",
            "Pred:[1 0 1 1 1 1 0 1]\n",
            "True:[1 0 1 1 1 1 0 1]\n",
            "110 + 79 = 189\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.035586921730201296\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "54 + 11 = 65\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.009843268901524203\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "3 + 40 = 43\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.016581680781756133\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "17 + 28 = 45\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.005643862490498928\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "65 + 33 = 98\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.012485325664162493\n",
            "Pred:[0 1 0 1 1 1 0 0]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "29 + 63 = 92\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.015589342854633365\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 0 0 0]\n",
            "6 + 34 = 40\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.015631845855162797\n",
            "Pred:[1 1 0 0 1 0 1 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "80 + 122 = 202\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.005752374016582964\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 0 1 0 0 1 0 1]\n",
            "37 + 0 = 37\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.019323362997115193\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "106 + 22 = 128\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.007588728325082271\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 0 1 1]\n",
            "117 + 110 = 227\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.008283778421108777\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "6 + 71 = 77\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.007697793859090421\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "74 + 79 = 153\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.011585110514218332\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "120 + 42 = 162\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.012225055932390793\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "38 + 53 = 91\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.011560878676648768\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "122 + 19 = 141\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.005297132298262463\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "74 + 25 = 99\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.0031843975751620433\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "107 + 36 = 143\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.006097910172116776\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "112 + 68 = 180\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.006719766872004771\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "116 + 22 = 138\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0052761223964378\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "46 + 99 = 145\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.004487891737758434\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "44 + 50 = 94\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0012323662462034855\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "109 + 113 = 222\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.004287242408409722\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "90 + 77 = 167\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.004032752240773165\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "107 + 79 = 186\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.004874450515695434\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[1 1 1 0 0 0 1 0]\n",
            "100 + 126 = 226\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.003975223030057759\n",
            "Pred:[1 0 1 1 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "126 + 59 = 185\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0022631911325949436\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "3 + 111 = 114\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0007084607404647221\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "1 + 85 = 86\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.001557598977187888\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "65 + 122 = 187\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0011296030846026154\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "19 + 22 = 41\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.000970722340268812\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "11 + 105 = 116\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.002060590824558479\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "15 + 37 = 52\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.003256009706266694\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "60 + 8 = 68\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.00154662584255219\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "93 + 98 = 191\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0012514995846873813\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "49 + 34 = 83\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.00197950428198442\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "98 + 69 = 167\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.002278832725082823\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "62 + 41 = 103\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.001236207727444\n",
            "Pred:[0 1 0 1 0 0 1 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "55 + 28 = 83\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OJO9muDhqQ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}